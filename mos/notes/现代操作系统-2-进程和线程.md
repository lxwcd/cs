现代操作系统 第二章 进程和线程

# 进程
-  A process is just an instance of an executing program, including the current values of the program counter, registers, and variables.

- 前台进程
foreground processes, that is, processes that interact with (human) users and perform work for them. 
- 后台进程
Processes that stay in the background to handle some activity such as email, Web pages, news, printing, and so on are called daemons.

Four principal events cause processes to be created:
1. System initialization.
2. Execution of a process-creation system call by a running process.
3. A user request to create a new process.
4. Initiation of a batch job.

## Process Creation
In UNIX, there is only one system call to create a new process: fork. 

This call creates an exact clone of the calling process. 
After the fork, the two processes, the parent and the child, have the same memory image, the same environment strings, and the same open files. 

After a process is created, the parent and child have their own distinct address spaces. 

Some UNIX implementations share the **program text** between the two since that cannot be modified.

Alternatively, the child may share all of the parent’s memory, but in that case the memory is shared **copy-on-write**, which means that whenever either of the two wants to modify part of the memory, that chunk of memory is explicitly copied first to make sure the modification occurs in a private memory area. 

No writable memory is shared. 

## Process Termination
通常造成进程终止的条件有：
1. Normal exit (voluntary).
such as execute **exit** system call
2. Error exit (voluntary).
3. Fatal error (involuntary).
4. Killed by another process (involuntary).

## Process Hierarchies
In some systems, when a process creates another process, the parent process and child process continue to be associated in certain ways. 
The child process can itself create more processes, forming a process hierarchy.

## Process States
![](img/2023-10-02-11-20-36.png)


***************

> [Process state](https://en.wikipedia.org/wiki/Process_state)
> [States of a Process in Operating Systems](https://www.geeksforgeeks.org/states-of-a-process-in-operating-systems/)

> These distinct states may not be recognized as such by the operating system kernel. However, they are a useful abstraction for the understanding of processes.

### Created
- The process awaits admission to the "ready" state.
- Admission will be approved or delayed by a long-term, or admission, scheduler.

- 需要申请一个空白的 PCB，完成资源分配

### Ready
- A "ready" or "waiting" process has been loaded into main memory and is awaiting execution on a CPU. 

### Running
- A process moves into the running state when it is chosen for execution.
- There is at most one running process per CPU or core.
- A process can run in either of the two modes, namely kernel mode or user mode.

### Blocked
- A process transitions to a blocked state when it cannot carry on without an external change in state or event occurring.
- For example, a process may block on a call to an I/O device such as a printer, if the printer is not available.
- Processes also commonly block when they require user input, or require access to a critical section which must be executed [atomically](https://stackoverflow.com/questions/15054086/what-does-atomic-mean-in-programming).
- Such critical sections are protected using a synchronization object such as a semaphore or mutex.


### Terminated
- A process may be terminated, either from the "running" state by completing its execution or by explicitly being killed.
- The terminated process remains in the process table as a zombie process until its parent process calls the `wait` system call to read its exit status, at which point the process is removed from the process table, finally ending the process's lifetime.
- If the parent failes to call `wait`, this process continues to consume the process table entry (concretely the process identifier or PID), and causes a resource leak.


### Additional process states
> Two additional states are available for processes in systems that support virtual memory. 
> In both of these states, processes are "stored" on secondary memory (typically a hard disk).

- 进程被**挂起**（suspended）且**不会被调度**。
A process **stops** as a result of receiving a **SIGSTOP**, **SIGTSTP**, **SIGTTIN**, or **SIGTTOU** signal, 
and it **remains** **stopped** **until** it receives a **SIGCONT** signal, at which point it becomes running again.

- 按 `Ctrl z` 可以让进程处于 suspended 的状态，相当于发送信号 `SIGSTOP` 


#### Swapped out and waiting
- suspended and waiting
- The process is removed from main memory and placed on external storage by the scheduler.
- It may be swapped back into the waiting state.
#### Swapped out and blocked
- suspended and blocked
- The process is both blocked and swapped out
- It may be swapped back in again under the same circumstances as a swapped out and waiting process.


## Implementation of Processes
To implement the process model, the operating system maintains a table (an array of structures), called the process table, with one entry per process. (Some authors call these entries process control blocks.) 

This entry contains important information about the process’state, including its program counter, stack pointer,
memory allocation, the status of its open files, its accounting and scheduling information, and everything else about the process that must be saved when the process is switched from running to ready or blocked state so that it can be restarted later as if it had never been stopped.

![](img/2023-10-02-11-53-24.png)

# 线程
Processes are used to group resources together; threads are the entities scheduled for execution on the CPU.
进程是资源分配的基本单位
线程是 CPU 调度的基本单位

## 为什么需要线程
The main reason for having threads is that in many applications, multiple activities are going on at once. 
Some of these may block from time to time. 
By decomposing such an application into multiple sequential threads that run in quasi-parallel, the programming model becomes simpler.

A second argument for having threads is that since they are lighter weight than processes, they are easier (i.e., faster) to create and destroy than processes.

Threads yield no performance gain when all of them are CPU bound, but when there is substantial computing and also substantial I/O, having threads allows these activities to overlap, thus speeding up the application.

Threads are useful on systems with multiple CPUs, where real parallelism is possible


## 线程之间共享和独占的资源

![](img/2023-10-07-11-03-42.png)

 
Each thread has its own stack. 
Each thread’s stack contains one frame for each procedure called but not yet returned from.
This frame contains the procedure’s local variables and the return address to use when the procedure call has finished.


## 线程状态
- `thread_create`
When multithreading is present, processes usually start with a single thread present. 
This thread has the ability to create new threads by calling a library procedure such as `thread_create`.

Sometimes threads are hierarchical, with a parent-child relationship, 
but often no such relationship exists, with all threads being equal.

With or without a hierarchical relationship, the creating thread is usually returned a thread identifier that names the new thread.

- `thread_exit`
When a thread has finished its work, it can exit by calling a library procedure, say, `thread_exit`.

- thread_yield
`thread_yield` allows a thread to voluntarily give up the CPU to let another thread run.

## 多线程需要考虑的问题
1. If the parent process has multiple threads, should the child also have
them? 

If not, the process may not function properly, since all of them may be essential.

If the child process gets as many threads as the parent, what happens if a thread in the parent was blocked on a read call, say, from the keyboard

2.  What happens if one thread closes a file while another one is still read-
ing from it?

## POSIX Threads
To make it possible to write portable threaded programs, IEEE has defined a standard for threads in IEEE standard 1003.1c. 
The threads package it defines is called Pthreads. Most UNIX systems support it. 

![](img/2023-10-07-11-21-39.png)


## Implementing Threads 
> [线程的实现](https://xiaolincoding.com/os/4_process/process_base.html#线程的实现)

There are two main places to implement threads: user space and the kernel.

![](img/2023-10-07-11-39-09.png)

### Implementing Threads in User Space
When threads are managed in user space, each process needs its own private thread table to keep track of the threads in that process. 

This table is analogous to the kernel’s process table, except that it keeps track only of the per-thread properties, such as each thread’s program counter, stack pointer, registers, state, and so forth. 

The thread table is managed by the run-time system.

优点：
- 用户空间实现的线程进行上下文切换相对进程切换很快
- They allow each process to have its own customized scheduling algorithm. 

缺点：
- First among these is the problem of how blocking system calls are implemented.
One of the main goals of having threads in the first place was to allow each one to use blocking calls, 
but to prevent one blocked thread from affecting the others.

一个线程发起系统调用而阻塞会影响进程中的其他线程

- Another alternative is available in the event that it is possible to tell in advance if a call will block.

- Somewhat analogous to the problem of blocking system calls is the problem of page faults.
If a thread causes a page fault, the kernel, unaware of even the existence of threads, 
naturally blocks the entire process until the disk I/O is complete, even though other threads might be runnable.01.

- Another problem with user-level thread packages is that if a thread starts running, no other thread in that process will ever run unless the first thread voluntarily gives up the CPU. 

一个线程开始运行后，除非它主动交出 CPU 使用权，否则进程中的其他线程无法运行，因为用户态线程不能由操作系统调度
进程内部可以可以自己做一些调度规则

### Implementing Threads in Kernel Space
The kernel has a thread table that keeps track of all the threads in the system. 

When a thread wants to create a new thread or destroy an existing thread, 
it makes a kernel call, which then does the creation or destruction by updating the kernel thread table.

优点：
一个线程因为系统调用阻塞，不会影响进程中的其他线程
CPU 根据线程调度

缺点：
操作系统维护线程表、线程控制块 TCB
线程的创建、切换和终止都是通过系统调用，系统开销大

### Hybrid Implementation
一个应用程序可以同时用内核线程和用户线程，一个内核线程可以对应多个用户线程，数量由用户定义

![](img/2023-10-07-13-06-24.png)

In this model, each kernel-level thread has some set of user-level threads that take turns using it.
只有内核线程能被 CPU 调度

## Scheduler Activations
调度程序激活，是操作系统调度和执行线程的一种机制，旨在改进多线程程序的性能和可伸缩性

The goals of the scheduler activation work are to mimic the functionality of kernel threads, but with the better performance and greater flexibility usually associated with threads packages implemented in user space. 

When scheduler activations are used, the kernel assigns a certain number of virtual processors to each process and lets the (user-space) run-time system allocate threads to processors.

virtual processors 的数量可以根据需要动态增加和减少

当一个线程阻塞时，内核通过 upcall 通知用户空间的 run-time system，passing as parameters on the stack the number of the thread in question and a description of the event that occurred. 
然后 run-time system 重新调度一个新线程执行，因此避免一个线程阻塞而影响进程中其他线程

### upcall
上调用，用于将控制权从低级别的执行环境传递到高级别的执行环境。

上调用通常发生在操作系统内核和应用程序之间，或者在较低级别的软件组件和较高级别的软件组件之间。当发生某种事件或需要上层处理时，低级别的环境会发起一个上调用，将控制权传递给较高级别的环境，以便执行相应的处理逻辑。

上调用的目的是向上层组件或环境报告事件、请求服务或通知状态变化等。高级别的执行环境可以是应用程序的用户空间、应用程序的库、操作系统的内核等。

上调用的过程通常涉及一些协议和机制，以确保正确的传递控制权和数据。这可能包括上下文切换、参数传递、状态保存和恢复等操作。

上调用在操作系统和应用程序之间起到了桥梁的作用，允许不同层次的软件组件进行交互和协作。它提供了一种灵活的机制，使得低级别的组件能够通知和请求高级别的组件，从而实现功能扩展、事件处理和系统管理等操作。

总之，上调用是一种将控制权从低级别的执行环境传递到高级别的执行环境的机制，用于报告事件、请求服务或通知状态变化等。它在计算机系统中起到了重要的协作和交互的作用。

# Interprocess Communication
进程间通信，IPC

进程间通信需要面临下面三个问题：
- 进程将怎么传递信息
传递信息在线程之间比较好处理，因为线程之间共享地址空间
- 处理多个进程竞争同一个资源的情况
- 多个进程之间运行可能有一定依赖关系，需要合适的顺序
如进程 B 可能需要进程 A 执行完成才能执行

第二个和第三个问题在多线程通信同样需要解决

## Race Conditions
多个进程一起访问共享资源可能导致竞争条件

To see how interprocess communication works in practice, let us now consider a simple but common example: a print spooler. 
When a process wants to print a file, it enters the file name in a special spooler directory. 
Another process, the printer daemon, periodically checks to see if there are any files to be printed, and if there are, it prints them and then removes their names from the directory.

Imagine that our spooler directory has a very large number of slots, numbered 0, 1, 2, ..., each one capable of holding a file name. 

Also imagine that there are two shared variables, `out`, which points to the next file to be printed, and `in`, which points to the next free slot in the directory. 
These two variables might well be kept in a two-word file available to all processes. 

![](img/2023-10-07-18-48-06.png)

见上图所示，可能发生下面情况：
1. 进程 A 读变量 `in` 的值后保存该值 7 到局部变量 `next_free_slot`中
2. 然后该进程所占的时钟周期用完，CPU 调度到进程 B 来运行
3. 进程 B 同样获取变量 `in` 的值，即 7 
4. 接着进程 B 保存一个文件名到 slot 7 然后将 `in` 的值设置为 8，接着做其他事
5. 等 CPU 又调度到进程 A 运行时，由于之前进程 A 保存了 `in` 的值为 7，因此将要写入的文件名写到 slot 7 中覆盖掉进程 B 写入的内容， 然后进程 A 将 `in` 设置为 8
6. 最后进程 B 写入的文件名将不会被打印

上面这种多个进程读写共享资源，最终的结果取决于谁在何时准确运行的情况，结果存在不确定性（indeterminate）叫做竞争条件，即 race conditons。

## Critical Regions
为了避免竞争条件，需要避免多个进程同时读写共享资源，即 mutual exclusion，互斥

临界区，即 critical region，指一段代码或代码块，其中包含对共享资源的访问

如果能避免多个进程同时进入临界区，则能避免竞争

![](img/2023-10-07-19-09-55.png)





然后保存到局部变量 `next_free_slot` 中

Process A reads in and stores the value, 7, in a local variable called next free slot. Just then a clock interrupt occurs and the CPU decides that proc-
ess A has run long enough, so it switches to process B. Process B also reads in and
also gets a 7. It, too, stores it in its local variable next free slot. At this instant
both processes think that the next available slot is 7.